_wandb:
    value:
        cli_version: 0.25.0
        e:
            xc3kplkfj8hqobwuw903d69myvpmb3kd:
                args:
                    - num_workers=0
                    - seed=7
                    - model=LSTM
                    - dataset=Qswap
                    - use_wandb=true
                    - wandb.group_name=LSTM
                    - num_epochs=100
                    - model_args.hidden_size=256
                codePath: main.py
                codePathLocal: main.py
                cpu_count: 48
                cpu_count_logical: 48
                cudaVersion: "12.5"
                disk:
                    /:
                        total: "405099057152"
                        used: "6933557248"
                email: singfor7012@gmail.com
                executable: /home1/aiphw227/miniconda3/envs/rnn/bin/python
                gpu: NVIDIA GeForce RTX 3090
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 10496
                      memoryTotal: "25769803776"
                      name: NVIDIA GeForce RTX 3090
                      uuid: GPU-5e3c537c-3957-8c49-bb9d-a4dc290ace6a
                host: n003.hpc
                memory:
                    total: "810198114304"
                os: Linux-4.18.0-553.5.1.el8_10.x86_64-x86_64-with-glibc2.28
                program: /gpfs/home1/aiphw227/Delay_RNN/code/main.py
                python: CPython 3.11.14
                root: /gpfs/home1/aiphw227/Delay_RNN/code
                slurm:
                    cluster_name: cluster
                    conf: /var/spool/slurmd/conf-cache/slurm.conf
                    cpu_bind: quiet,mask_cpu:0x3FF0003F000F
                    cpu_bind_list: "0x3FF0003F000F"
                    cpu_bind_type: 'mask_cpu:'
                    cpu_bind_verbose: quiet
                    cpus_on_node: "20"
                    cpus_per_task: "20"
                    gpus_on_node: "1"
                    gtids: "0"
                    job_account: uos
                    job_cpus_per_node: "20"
                    job_end_time: "1772287828"
                    job_gid: "100"
                    job_group: users
                    job_id: "545885"
                    job_name: bash
                    job_nodelist: n003
                    job_num_nodes: "1"
                    job_partition: gpu1
                    job_qos: node10_cpu640
                    job_start_time: "1772115028"
                    job_uid: "1291"
                    job_user: aiphw227
                    jobid: "545885"
                    launch_node_ipaddr: 192.168.140.5
                    localid: "0"
                    nnodes: "1"
                    nodeid: "0"
                    nodelist: n003
                    nprocs: "1"
                    ntasks: "1"
                    prio_process: "0"
                    procid: "0"
                    pty_port: "39271"
                    pty_win_col: "285"
                    pty_win_row: "30"
                    srun_comm_host: 192.168.140.5
                    srun_comm_port: "35859"
                    step_gpus: "0"
                    step_id: "0"
                    step_launcher_port: "35859"
                    step_nodelist: n003
                    step_num_nodes: "1"
                    step_num_tasks: "1"
                    step_tasks_per_node: "1"
                    stepid: "0"
                    submit_dir: /gpfs/home1/aiphw227
                    submit_host: gate2.hpc
                    task_pid: "2261462"
                    tasks_per_node: "1"
                    topology_addr: n003
                    topology_addr_pattern: node
                    tres_per_task: cpu:20
                    umask: "0022"
                startedAt: "2026-02-26T17:46:02.699361Z"
                writerId: xc3kplkfj8hqobwuw903d69myvpmb3kd
        m: []
        python_version: 3.11.14
        t:
            "1":
                - 1
                - 50
                - 51
            "2":
                - 1
                - 50
                - 51
            "3":
                - 13
                - 14
                - 16
            "4": 3.11.14
            "5": 0.25.0
            "12": 0.25.0
            "13": linux-x86_64
batch_size:
    value: 512
dataset:
    value:
        _target_: datasets.Qswap.Qswap
        max_seq_len: 10
        min_seq_len: 5
        one_hot_dim: 10
lr:
    value: 0.001
model:
    value:
        _target_: models.LSTM.LSTM
model_args:
    value:
        hidden_size: 256
        num_layers: 1
num_epochs:
    value: 100
num_workers:
    value: 0
seed:
    value: 7
use_lr_scheduler:
    value: true
use_wandb:
    value: true
wandb:
    value:
        entity: CIDA
        group_name: LSTM
