{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msizzflair97\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/delayed-rnn/wandb/run-20260225_150508-j7ar8yu7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sizzflair97/QSWAP_RNN/runs/j7ar8yu7' target=\"_blank\">LEARNABLE_DELAY_RNN</a></strong> to <a href='https://wandb.ai/sizzflair97/QSWAP_RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sizzflair97/QSWAP_RNN' target=\"_blank\">https://wandb.ai/sizzflair97/QSWAP_RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sizzflair97/QSWAP_RNN/runs/j7ar8yu7' target=\"_blank\">https://wandb.ai/sizzflair97/QSWAP_RNN/runs/j7ar8yu7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch, wandb\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.config import Config, ModelType\n",
    "from utils.model.seq2seq import Seq2SeqOutput, ThinkingRNN, ThinkingLSTM, ThinkingLearnableDelayRNN\n",
    "from utils.data import SwapDataset, collate_fn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "config = Config(\n",
    "    model_type=ModelType.DelayedRNN,\n",
    "    epochs=100,\n",
    "    learning_rate=0.01,\n",
    "    max_think_steps=100,\n",
    "    batch_size=32,\n",
    "    input_size=11,\n",
    "    hidden_size=256,\n",
    "    num_classes=10,\n",
    "    max_delay=40,\n",
    "    seq_min=5,\n",
    "    seq_max=20,\n",
    "    device=torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "run = wandb.init(project=\"QSWAP_RNN\", name=f\"{config.model_type.name}\", config=asdict(config))\n",
    "run.__enter__()\n",
    "\n",
    "print(f\"Using device: {config.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe335cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 10000 # 한 Epoch에 사용할 데이터 수\n",
    "train_dataset = SwapDataset(size=DATASET_SIZE, k=config.input_size-1, min_len=config.seq_min, max_len=config.seq_max)\n",
    "val_dataset = SwapDataset(size=DATASET_SIZE//10, k=config.input_size-1, min_len=config.seq_min, max_len=config.seq_max)\n",
    "test_dataset = SwapDataset(size=DATASET_SIZE//10, k=config.input_size-1, min_len=config.seq_min, max_len=config.seq_max)\n",
    "\n",
    "# DataLoader 생성 (collate_fn 등록 필수!)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size,       # 확인용으로 작은 배치\n",
    "    shuffle=True,       # 학습 시 셔플 추천\n",
    "    collate_fn=collate_fn # 우리가 만든 패딩 함수 적용\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e466f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f75e7525b24b38b4444fce6512bc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1831c28d881640d696eebd41e5e7a973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy after Epoch 1: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ea0153461b493a8eef40921b273a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42) # 재현성을 위해 시드 고정\n",
    "\n",
    "match config.model_type:\n",
    "    case ModelType.RNN:\n",
    "        model = ThinkingRNN(config.input_size, config.hidden_size, config.num_classes, config=config).to(config.device)\n",
    "    case ModelType.LSTM:\n",
    "        model = ThinkingLSTM(config.input_size, config.hidden_size, config.num_classes, config=config).to(config.device)\n",
    "    case ModelType.DelayedRNN:\n",
    "        model = ThinkingLearnableDelayRNN(config.input_size, config.hidden_size, config.num_classes, max_delay=config.max_delay, config=config).to(config.device)\n",
    "    case _:\n",
    "        raise ValueError(f\"Unknown model type: {config.model_type}\")\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs * len(train_loader))\n",
    "scheduler = optim.lr_scheduler.ConstantLR(optimizer, factor=1.0, total_iters=0) # CosineAnnealingLR로 대체\n",
    "\n",
    "# 5. 학습 루프\n",
    "for epoch in tqdm(range(config.epochs), desc=\"Epochs\"):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for i, (inputs, targets, lengths) in tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Batches\", leave=False):\n",
    "        inputs, targets, lengths = inputs.to(config.device), targets.to(config.device), lengths.to(config.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 모델 Forward\n",
    "        seq2seq_out:Seq2SeqOutput = model(inputs, lengths, N=targets.size(1))\n",
    "        outputs = seq2seq_out.outputs  # [Batch, Max_Len, K]\n",
    "        think_steps = seq2seq_out.think_steps  # [Batch]\n",
    "        \n",
    "        # Loss\n",
    "        # outputs: [Batch, Max_Len, K] -> Flatten\n",
    "        # targets: [Batch, Max_Len] -> Flatten (-1은 ignore_index 처리됨)\n",
    "        # loss = criterion(outputs.reshape(config.batch_size, config.seq_max, config.num_classes), targets.reshape(-1))\n",
    "        valid_mask = targets != -1\n",
    "        outputs_flat = outputs[valid_mask].view(-1, config.num_classes) \n",
    "        targets_flat = targets[valid_mask]\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs_flat, targets_flat)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            valid_mask = targets_flat != -1\n",
    "            if valid_mask.sum() > 0:\n",
    "                predictions = outputs_flat.argmax(dim=-1)\n",
    "                correct_predictions = (predictions[valid_mask] == targets_flat[valid_mask]).float()\n",
    "                accuracy = correct_predictions.mean().item()\n",
    "            else:\n",
    "                accuracy = 0.0\n",
    "        \n",
    "        wandb.log({\"Loss/Train\": loss.item(),\n",
    "                \"Accuracy/Train\": accuracy,\n",
    "                \"Think_Steps/Train\": think_steps.float().mean().item(),\n",
    "                \"Learning_Rate\": scheduler.get_last_lr()[0]})\n",
    "                \n",
    "        if (i+1) % 300 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{config.epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Acc: {accuracy:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        think_steps_list = []\n",
    "        for inputs, targets, lengths in tqdm(val_loader, desc=\"Validation Batches\", leave=False):\n",
    "            inputs, targets, lengths = inputs.to(config.device), targets.to(config.device), lengths.to(config.device)\n",
    "            \n",
    "            seq2seq_out:Seq2SeqOutput = model(inputs, lengths, N=targets.size(1))\n",
    "            outputs = seq2seq_out.outputs  # [Batch, Max_Len, K]\n",
    "            think_steps = seq2seq_out.think_steps  # [Batch]\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "            total += targets.size(0)\n",
    "            correct += torch.all(predicted == targets, dim=1).sum().item()\n",
    "            think_steps_list.extend(think_steps.tolist())\n",
    "            \n",
    "        wandb.log({\"Accuracy/Validation\": 100 * correct / total,\n",
    "                   \"Think_Steps/Validation\": sum(think_steps_list) / len(think_steps_list) if think_steps_list else 0})\n",
    "        print(f'Validation Accuracy after Epoch {epoch+1}: {100 * correct / total:.2f}%')\n",
    "            \n",
    "# 6. 평가 루프\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    think_steps_list = []\n",
    "    for inputs, targets, lengths in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs, targets, lengths = inputs.to(config.device), targets.to(config.device), lengths.to(config.device)\n",
    "        \n",
    "        seq2seq_out:Seq2SeqOutput = model(inputs, lengths, N=targets.size(1))\n",
    "        outputs = seq2seq_out.outputs  # [Batch, Max_Len, K]\n",
    "        think_steps = seq2seq_out.think_steps  # [Batch]\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 2)\n",
    "        total += targets.size(0)\n",
    "        correct += torch.all(predicted == targets, dim=1).sum().item()\n",
    "        think_steps_list.extend(think_steps.tolist())\n",
    "        \n",
    "    wandb.log({\"Accuracy/Test\": 100 * correct / total,\n",
    "                \"Think_Steps/Test\": sum(think_steps_list) / len(think_steps_list) if think_steps_list else 0})\n",
    "\n",
    "    print(f'Test Accuracy of the RNN on the 10000 test images (QSWAP): {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048fad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 20, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53475a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 20, 10]), torch.Size([52, 20]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3525f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy/Test</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>Accuracy/Train</td><td>▁▁▃▄▄▅▅▆▆▆▆▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇█▇▇▇█▇██▇▇█▇▇▇</td></tr><tr><td>Accuracy/Validation</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/Train</td><td>██▇▆▆▅▅▄▃▄▄▄▃▄▃▂▂▂▃▂▃▂▃▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy/Test</td><td>0</td></tr><tr><td>Accuracy/Train</td><td>0.26496</td></tr><tr><td>Accuracy/Validation</td><td>0</td></tr><tr><td>Loss/Train</td><td>1.98363</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LEARNABLE_DELAY_RNN</strong> at: <a href='https://wandb.ai/sizzflair97/QSWAP_RNN/runs/fuuh52ww' target=\"_blank\">https://wandb.ai/sizzflair97/QSWAP_RNN/runs/fuuh52ww</a><br> View project at: <a href='https://wandb.ai/sizzflair97/QSWAP_RNN' target=\"_blank\">https://wandb.ai/sizzflair97/QSWAP_RNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260225_011353-fuuh52ww/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.__exit__(None, None, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
