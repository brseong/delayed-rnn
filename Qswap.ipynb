{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af44d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msizzflair97\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/delayed-rnn/wandb/run-20260225_005807-07927c86</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sizzflair97/QSWAP_RNN/runs/07927c86' target=\"_blank\">LEARNABLE_DELAY_RNN</a></strong> to <a href='https://wandb.ai/sizzflair97/QSWAP_RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sizzflair97/QSWAP_RNN' target=\"_blank\">https://wandb.ai/sizzflair97/QSWAP_RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sizzflair97/QSWAP_RNN/runs/07927c86' target=\"_blank\">https://wandb.ai/sizzflair97/QSWAP_RNN/runs/07927c86</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch, wandb\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.config import Config, ModelType\n",
    "from utils.model.seq2seq import ThinkingRNN, ThinkingLSTM, ThinkingLearnableDelayRNN\n",
    "from utils.data import SwapDataset, collate_fn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "config = Config()\n",
    "config.model_type = ModelType.LEARNABLE_DELAY_RNN\n",
    "config.input_size = 11\n",
    "config.num_classes = 10\n",
    "config.max_delay = 20\n",
    "config.seq_min = 5         # 최소 시퀀스 길이\n",
    "config.seq_max = 20        # 최대 시퀀스 길이\n",
    "config.device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "run = wandb.init(project=\"QSWAP_RNN\", name=f\"{config.model_type.name}\", config=asdict(config))\n",
    "run.__enter__()\n",
    "\n",
    "print(f\"Using device: {config.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe335cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 5000 # 한 Epoch에 사용할 데이터 수\n",
    "train_dataset = SwapDataset(size=DATASET_SIZE, k=config.input_size-1, min_len=config.seq_min, max_len=config.seq_max)\n",
    "test_dataset = SwapDataset(size=DATASET_SIZE//10, k=config.input_size-1, min_len=config.seq_min, max_len=config.seq_max)\n",
    "\n",
    "# DataLoader 생성 (collate_fn 등록 필수!)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size,       # 확인용으로 작은 배치\n",
    "    shuffle=True,       # 학습 시 셔플 추천\n",
    "    collate_fn=collate_fn # 우리가 만든 패딩 함수 적용\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e466f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ThinkingLearnableDelayRNN.__init__() got multiple values for argument 'max_delay'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m     model = ThinkingLSTM(config.input_size, config.hidden_size, config.num_classes, config=config).to(config.device)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mcase\u001b[39;00m ModelType.LEARNABLE_DELAY_RNN:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     model = \u001b[43mThinkingLearnableDelayRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m.to(config.device)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.model_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: ThinkingLearnableDelayRNN.__init__() got multiple values for argument 'max_delay'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42) # 재현성을 위해 시드 고정\n",
    "\n",
    "match config.model_type:\n",
    "    case ModelType.RNN:\n",
    "        model = ThinkingRNN(config.input_size, config.hidden_size, config.num_classes, config=config).to(config.device)\n",
    "    case ModelType.LSTM:\n",
    "        model = ThinkingLSTM(config.input_size, config.hidden_size, config.num_classes, config=config).to(config.device)\n",
    "    case ModelType.LEARNABLE_DELAY_RNN:\n",
    "        model = ThinkingLearnableDelayRNN(config.input_size, config.hidden_size, config.num_classes, max_delay=config.max_delay, config=config).to(config.device)\n",
    "    case _:\n",
    "        raise ValueError(f\"Unknown model type: {config.model_type}\")\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "# 5. 학습 루프\n",
    "for epoch in tqdm(range(config.epochs), desc=\"Epochs\"):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for i, (inputs, targets, lengths) in tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Batches\", leave=False):\n",
    "        inputs, targets = inputs.to(config.device), targets.to(config.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 모델 Forward\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Loss\n",
    "        # outputs: [Batch, Max_Len, K] -> Flatten\n",
    "        # targets: [Batch, Max_Len] -> Flatten (-1은 ignore_index 처리됨)\n",
    "        # loss = criterion(outputs.reshape(config.batch_size, config.seq_max, config.num_classes), targets.reshape(-1))\n",
    "        valid_mask = targets != -1\n",
    "        outputs_flat = outputs[valid_mask].view(-1, config.num_classes) \n",
    "        targets_flat = targets[valid_mask]\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs_flat, targets_flat)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            valid_mask = targets_flat != -1\n",
    "            if valid_mask.sum() > 0:\n",
    "                predictions = outputs_flat.argmax(dim=-1)\n",
    "                correct_predictions = (predictions[valid_mask] == targets_flat[valid_mask]).float()\n",
    "                accuracy = correct_predictions.mean().item()\n",
    "            else:\n",
    "                accuracy = 0.0\n",
    "        \n",
    "        wandb.log({\"Loss/Train\": loss.item(),\n",
    "                \"Accuracy/Train\": accuracy})\n",
    "                \n",
    "        if (i+1) % 300 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{config.epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Acc: {accuracy:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, targets, lengths in test_loader:\n",
    "            inputs, targets = inputs.to(config.device), targets.to(config.device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "            total += targets.size(0)\n",
    "            correct += torch.all(predicted == targets, dim=1).sum().item()\n",
    "        \n",
    "        wandb.log({\"Accuracy/Validation\": 100 * correct / total})\n",
    "        print(f'Validation Accuracy after Epoch {epoch+1}: {100 * correct / total:.2f}%')\n",
    "            \n",
    "# 6. 평가 루프\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets, lengths in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs, targets = inputs.to(config.device), targets.to(config.device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)\n",
    "        total += targets.size(0)\n",
    "        correct += torch.all(predicted == targets, dim=1).sum().item()\n",
    "        wandb.log({\"Accuracy/Test\": 100 * correct / total})\n",
    "\n",
    "    print(f'Test Accuracy of the RNN on the 10000 test images (QSWAP): {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048fad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53475a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 23, 10]), torch.Size([64, 20]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3525f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.__exit__(None, None, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
