{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msizzflair97\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/delayed-rnn/wandb/run-20260211_145356-qgm18240</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sizzflair97/QSWAP_RNN/runs/qgm18240' target=\"_blank\">LearnableDelayRNN_QSWAP</a></strong> to <a href='https://wandb.ai/sizzflair97/QSWAP_RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sizzflair97/QSWAP_RNN' target=\"_blank\">https://wandb.ai/sizzflair97/QSWAP_RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sizzflair97/QSWAP_RNN/runs/qgm18240' target=\"_blank\">https://wandb.ai/sizzflair97/QSWAP_RNN/runs/qgm18240</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:4\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch, wandb\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.config import Config, ModelType\n",
    "from utils.model.seq2seq import SimpleRNN, SimpleLSTM, LearnableDelayRNN\n",
    "from utils.data import SwapDataset, collate_fn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "config = Config()\n",
    "config.model_type = ModelType.LEARNABLE_DELAY_RNN\n",
    "config.input_size = 11\n",
    "config.num_classes = 10\n",
    "config.max_delay = 20\n",
    "config.seq_min = 5         # 최소 시퀀스 길이\n",
    "config.seq_max = 20        # 최대 시퀀스 길이\n",
    "config.device = torch.device(\"cuda:4\")\n",
    "\n",
    "run = wandb.init(project=\"QSWAP_RNN\", name=\"LearnableDelayRNN_QSWAP\", config=asdict(config))\n",
    "run.__enter__()\n",
    "\n",
    "print(f\"Using device: {config.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe335cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 5000 # 한 Epoch에 사용할 데이터 수\n",
    "train_dataset = SwapDataset(size=DATASET_SIZE, k=config.input_size-1, min_len=config.seq_min, max_len=config.seq_max)\n",
    "test_dataset = SwapDataset(size=DATASET_SIZE//10, k=config.input_size-1, min_len=config.seq_min, max_len=config.seq_max)\n",
    "\n",
    "# DataLoader 생성 (collate_fn 등록 필수!)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size,       # 확인용으로 작은 배치\n",
    "    shuffle=True,       # 학습 시 셔플 추천\n",
    "    collate_fn=collate_fn # 우리가 만든 패딩 함수 적용\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e466f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9740af2300416faed8203fd644f3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c9b6f77e3042218bd3c6bc0013632b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (736) to match target batch_size (1280).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     26\u001b[39m outputs = model(inputs)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# outputs: [Batch, Max_Len, K] -> Flatten\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# targets: [Batch, Max_Len] -> Flatten (-1은 ignore_index 처리됨)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseq_max\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m loss.backward()\n\u001b[32m     34\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/delayed-rnn/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/delayed-rnn/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/delayed-rnn/venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1362\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m   1361\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs the forward pass.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1364\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/delayed-rnn/venv/lib/python3.12/site-packages/torch/nn/functional.py:3504\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3503\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3506\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3508\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pyrefly: ignore [bad-argument-type]\u001b[39;49;00m\n\u001b[32m   3509\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3512\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Expected input batch_size (736) to match target batch_size (1280)."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42) # 재현성을 위해 시드 고정\n",
    "\n",
    "match config.model_type:\n",
    "    case ModelType.SIMPLE_RNN:\n",
    "        model = SimpleRNN(config.input_size, config.hidden_size, config.num_classes, config=config).to(config.device)\n",
    "    case ModelType.SIMPLE_LSTM:\n",
    "        model = SimpleLSTM(config.input_size, config.hidden_size, config.num_classes, config=config).to(config.device)\n",
    "    case ModelType.LEARNABLE_DELAY_RNN:\n",
    "        model = LearnableDelayRNN(config.batch_size, config.input_size, config.hidden_size, config.num_classes, max_delay=config.max_delay, config=config).to(config.device)\n",
    "    case _:\n",
    "        raise ValueError(f\"Unknown model type: {config.model_type}\")\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "# 5. 학습 루프\n",
    "for epoch in tqdm(range(config.epochs), desc=\"Epochs\"):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for i, (inputs, targets, lengths) in tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Batches\", leave=False):\n",
    "        inputs, targets = inputs.to(config.device), targets.to(config.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 모델 Forward\n",
    "        outputs = model(inputs, config.seq_max)\n",
    "        \n",
    "        # Loss\n",
    "        # outputs: [Batch, Max_Len, K] -> Flatten\n",
    "        # targets: [Batch, Max_Len] -> Flatten (-1은 ignore_index 처리됨)\n",
    "        loss = criterion(outputs.reshape(-1, config.seq_max), targets.reshape(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        wandb.log({\"Loss/Train\": loss.item(),\n",
    "                   \"Accuracy/Train\": (outputs.argmax(dim=2) == targets).float().mean().item()})\n",
    "        if (i+1) % 300 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{config.epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, targets, lengths in test_loader:\n",
    "            inputs, targets = inputs.to(config.device), targets.to(config.device)\n",
    "            \n",
    "            outputs = model(inputs, lengths)\n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        \n",
    "        wandb.log({\"Accuracy/Validation\": 100 * correct / total})\n",
    "        print(f'Validation Accuracy after Epoch {epoch+1}: {100 * correct / total:.2f}%')\n",
    "            \n",
    "# 6. 평가 루프\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets, lengths in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs, targets = inputs.to(config.device), targets.to(config.device)\n",
    "        \n",
    "        outputs = model(inputs, lengths)\n",
    "        _, predicted = torch.max(outputs.data, 2)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        wandb.log({\"Accuracy/Test\": 100 * correct / total})\n",
    "\n",
    "    print(f'Test Accuracy of the RNN on the 10000 test images (PSMNIST): {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53475a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 23, 10]), torch.Size([64, 20]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3525f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.__exit__(None, None, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
